{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "A100"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "# @title SFT Training\n",
        "'''\n",
        "=====================================================================================================\n",
        "This training script was originally developed and optimized for execution within Google Colab,\n",
        "relying heavily on Google Drive for persistent storage, Colab-specific authentication mechanisms,\n",
        "and other environment-dependent utilities. As a result, the initial implementation included\n",
        "Drive-mounted checkpoint directories, CSV logging to Drive, and secret-based Hugging Face login via\n",
        "Colab‚Äôs userdata API. While these components streamlined experimentation within a Colab workflow,\n",
        "they also made the script less portable and harder to reproduce in general compute environments\n",
        "such as local machines, cloud VMs, or managed training clusters.\n",
        "\n",
        "You can refactor the current version and remove the above mentioned Colab-specific assumptions,\n",
        "replacing them with environment-agnostic paths, standard Hugging Face authentication, and fully\n",
        "general dataset/model loading logic so the script can run consistently anywhere while retaining\n",
        "the same behavior and training methodology.\n",
        "=====================================================================================================\n",
        "'''\n",
        "'''\n",
        "=====================================================================================================\n",
        "This SFT model was trained on a preference dataset using only the preferred (chosen) responses\n",
        "because of research purposes. SFT models are advised to be trained only on 'prompt-response' dataset.\n",
        "=====================================================================================================\n",
        "'''\n",
        "# ==========================================\n",
        "# 1. Install Dependencies\n",
        "# ==========================================\n",
        "print(\"‚è≥ Installing libraries...\")\n",
        "!pip install -q -U transformers datasets trl accelerate huggingface_hub\n",
        "\n",
        "'''\n",
        "The training was conducted using the following library versions at the time:\n",
        "Accelerate: 0.28.0\n",
        "Hugging Face Hub: 0.17.1\n",
        "TRL: 0.25.1\n",
        "Transformers: 4.57.3\n",
        "Pytorch: 2.9.0+cu126\n",
        "Datasets: 4.4.1\n",
        "Tokenizers: 0.22.1\n",
        "'''\n",
        "\n",
        "import torch\n",
        "import os\n",
        "import csv\n",
        "from google.colab import drive\n",
        "from datasets import load_dataset\n",
        "from transformers import (\n",
        "    AutoModelForCausalLM,\n",
        "    AutoTokenizer,\n",
        "    TrainerCallback\n",
        ")\n",
        "from trl import SFTTrainer, SFTConfig\n",
        "from huggingface_hub import login\n",
        "from google.colab import userdata\n",
        "\n",
        "# ==========================================\n",
        "# 2. Setup Drive & Login\n",
        "# ==========================================\n",
        "# Mount Drive\n",
        "print(\"\\nüìÇ Mounting Google Drive...\")\n",
        "drive.mount(\"/content/drive\")\n",
        "\n",
        "# Define Paths\n",
        "DRIVE_ROOT = \"/content/drive/MyDrive/SFT-Training\"\n",
        "CHECKPOINT_DIR = f\"{DRIVE_ROOT}/checkpoints\"\n",
        "LOG_FILE_PATH = f\"{DRIVE_ROOT}/training_logs.csv\"\n",
        "\n",
        "print(f\"üìÇ Checkpoints will be saved to: {CHECKPOINT_DIR}\")\n",
        "print(f\"üìÑ Logs will be saved to: {LOG_FILE_PATH}\")\n",
        "\n",
        "# Create directories and initialize the CSV log header if missing\n",
        "if not os.path.exists(DRIVE_ROOT):\n",
        "    os.makedirs(DRIVE_ROOT)\n",
        "\n",
        "if not os.path.exists(LOG_FILE_PATH):\n",
        "    with open(LOG_FILE_PATH, mode='w', newline='') as f:\n",
        "        writer = csv.writer(f)\n",
        "        writer.writerow([\"Step\", \"Epoch\", \"Training Loss\"])\n",
        "\n",
        "# Hugging Face Login\n",
        "print(\"\\nüîë Logging in to Hugging Face...\")\n",
        "try:\n",
        "    hf_token = userdata.get('HF_TOKEN')\n",
        "    login(token=hf_token, add_to_git_credential=True)\n",
        "    print(\"‚úÖ Logged in via Colab Secret.\")\n",
        "except:\n",
        "  print(\"‚ö†Ô∏è Secret 'HF_TOKEN' not found. Falling back to manual input.\")\n",
        "  login(add_to_git_credential=True)\n",
        "\n",
        "# ==========================================\n",
        "# 3. Define Custom Logging Callback\n",
        "# ==========================================\n",
        "class DriveLoggingCallback(TrainerCallback):\n",
        "    def on_log(self, args, state, control, logs=None, **kwargs):\n",
        "        if logs and \"loss\" in logs:\n",
        "            with open(LOG_FILE_PATH, mode='a', newline='') as f:\n",
        "                writer = csv.writer(f)\n",
        "                writer.writerow([state.global_step, logs.get(\"epoch\"), logs[\"loss\"]])\n",
        "\n",
        "# ==========================================\n",
        "# 4. Configuration\n",
        "# ==========================================\n",
        "MODEL_NAME = \"Qwen/Qwen3-0.6B-Base\"\n",
        "DATASET_NAME = \"Jennny/helpsteer2-helpfulness-preference\" # this is a variant of the HelpSteer2 dataset having only the helpfulness attribute\n",
        "REPO_NAME = \"your-username/qwen3-0.6b-SFT\" # this naming is arbitrary\n",
        "MAX_LENGTH = 2048\n",
        "\n",
        "# All hyperparameters can be modified as suitable\n",
        "# Batch 8 * Accum 4 = Effective Batch Size 32\n",
        "# This prevents OOM errors that occur with Batch 16 in FP32 (A100 40GB was used)\n",
        "BATCH_SIZE = 8\n",
        "GRAD_ACCUMULATION = 4   # Effective Batch Size = 32\n",
        "LEARNING_RATE = 2e-5\n",
        "LOGGING_STEPS = 20      # Log every 20 steps\n",
        "\n",
        "# ==========================================\n",
        "# 5. Dataset Loading & Filtering\n",
        "# ==========================================\n",
        "print(f\"Loading and Preparing dataset: {DATASET_NAME}...\")\n",
        "dataset = load_dataset(DATASET_NAME, split=\"train\")\n",
        "\n",
        "# Identify the correct score column (varies by dataset version)\n",
        "score_col = \"chosen_score\"\n",
        "if score_col not in dataset.column_names:\n",
        "    possible = [c for c in dataset.column_names if \"score\" in c or \"rating\" in c]\n",
        "    if possible: score_col = possible[0]\n",
        "\n",
        "# We filter out low-quality data so the model only learns from \"helpful\" examples (Score >= 3)\n",
        "try:\n",
        "    dataset = dataset.filter(lambda x: x[score_col] >= 3)\n",
        "    print(f\"‚úÖ Filtered dataset (Score >= 3): {len(dataset)} samples\")\n",
        "except KeyError:\n",
        "    print(\"‚ö†Ô∏è Warning: Score column not found. Skipping filter.\")\n",
        "\n",
        "# ==========================================\n",
        "# 6. Formatting\n",
        "# ==========================================\n",
        "print(\"\\n‚öôÔ∏è Formatting dataset...\")\n",
        "tokenizer = AutoTokenizer.from_pretrained(MODEL_NAME, trust_remote_code=True)\n",
        "if tokenizer.pad_token is None:\n",
        "    tokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "def format_to_text_column(example):\n",
        "    \"\"\"\n",
        "    Converts the dataset into a standard SFT format:\n",
        "    User: <prompt> \\n\\n Assistant: <response> <EOS>\n",
        "    \"\"\"\n",
        "    chosen_raw = example['chosen']\n",
        "    if isinstance(chosen_raw, list):\n",
        "        prompt_text = chosen_raw[0]['content']\n",
        "        response_text = chosen_raw[1]['content']\n",
        "    else:\n",
        "        prompt_text = \"\"\n",
        "        response_text = str(chosen_raw)\n",
        "\n",
        "    text = f\"User: {prompt_text}\\n\\nAssistant: {response_text}{tokenizer.eos_token}\"\n",
        "    return {\"text\": text}\n",
        "\n",
        "# We use 'remove_columns' to delete the original 'chosen'/'rejected' fields.\n",
        "# This forces the SFTTrainer to look only at our new 'text' column, preventing errors.\n",
        "formatted_dataset = dataset.map(\n",
        "    format_to_text_column,\n",
        "    remove_columns=dataset.column_names\n",
        ")\n",
        "\n",
        "# ==========================================\n",
        "# 7. Model Loading\n",
        "# ==========================================\n",
        "print(f\"\\nüß† Loading Model: {MODEL_NAME} (FP32)...\")\n",
        "# AutoModelForCausalLM is used for text generation (Next Token Prediction)\n",
        "model = AutoModelForCausalLM.from_pretrained(\n",
        "    MODEL_NAME,\n",
        "    torch_dtype=torch.float32,   # FP32 used for stability\n",
        "    trust_remote_code=True,\n",
        "    device_map=\"auto\"\n",
        ")\n",
        "\n",
        "# ==========================================\n",
        "# 8. Training\n",
        "# ==========================================\n",
        "training_args = SFTConfig(\n",
        "    output_dir=CHECKPOINT_DIR, # <--- Saving directly to Drive\n",
        "    per_device_train_batch_size=BATCH_SIZE,\n",
        "    gradient_accumulation_steps=GRAD_ACCUMULATION,\n",
        "    per_device_eval_batch_size=BATCH_SIZE,\n",
        "    num_train_epochs=2,\n",
        "    learning_rate=LEARNING_RATE,\n",
        "    warmup_ratio=0.1,\n",
        "    logging_steps=LOGGING_STEPS,\n",
        "    save_strategy=\"steps\",\n",
        "    save_steps=100,          # Save a checkpoint to Drive every 100 steps\n",
        "    save_total_limit=2,      # Keep only the last 2 checkpoints to save Drive space\n",
        "    packing=False,           # Disabled to avoid Flash Attention requirements/warnings\n",
        "    bf16=False, # FP32\n",
        "    fp16=False, # FP32\n",
        "    push_to_hub=True,\n",
        "    hub_model_id=REPO_NAME,\n",
        "    report_to=\"none\",\n",
        "    dataset_text_field=\"text\",\n",
        "    gradient_checkpointing=True,   # Saves memory by trading compute speed\n",
        ")\n",
        "\n",
        "# Manually set max_seq_length (Required for this TRL 0.25.1 version's SFTTrainer)\n",
        "training_args.max_seq_length = MAX_LENGTH\n",
        "\n",
        "trainer = SFTTrainer(\n",
        "    model=model,\n",
        "    processing_class=tokenizer, # 'processing_class' replaces 'tokenizer' in newer TRL versions (v0.12+)\n",
        "    args=training_args,\n",
        "    train_dataset=formatted_dataset,\n",
        "    callbacks=[DriveLoggingCallback()],\n",
        ")\n",
        "\n",
        "print(\"\\nüöÄ Starting SFT Training...\")\n",
        "trainer.train()\n",
        "\n",
        "# ==========================================\n",
        "# 9. Push to Hub\n",
        "# ==========================================\n",
        "print(\"\\n‚òÅÔ∏è Pushing final SFT model to Hub...\")\n",
        "trainer.push_to_hub()\n",
        "print(f\"‚úÖ DONE! Model uploaded to: https://huggingface.co/{REPO_NAME}\")"
      ],
      "metadata": {
        "id": "ys7AVWXAjI6R",
        "cellView": "form"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}