{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":31193,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"pip install -q -U bitsandbytes trl ","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-11-27T13:13:09.782188Z","iopub.execute_input":"2025-11-27T13:13:09.782398Z","iopub.status.idle":"2025-11-27T13:14:36.130566Z","shell.execute_reply.started":"2025-11-27T13:13:09.782374Z","shell.execute_reply":"2025-11-27T13:14:36.129827Z"}},"outputs":[{"name":"stdout","text":"\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.0/44.0 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.4/59.4 MB\u001b[0m \u001b[31m32.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m465.5/465.5 kB\u001b[0m \u001b[31m26.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m5.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m95.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m84.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m49.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m3.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m9.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m97.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.0/12.0 MB\u001b[0m \u001b[31m119.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.7/47.7 MB\u001b[0m \u001b[31m43.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m89.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nbigframes 2.12.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\npylibcudf-cu12 25.2.2 requires pyarrow<20.0.0a0,>=14.0.0; platform_machine == \"x86_64\", but you have pyarrow 22.0.0 which is incompatible.\ncudf-cu12 25.2.2 requires pyarrow<20.0.0a0,>=14.0.0; platform_machine == \"x86_64\", but you have pyarrow 22.0.0 which is incompatible.\nbigframes 2.12.0 requires rich<14,>=12.4.4, but you have rich 14.2.0 which is incompatible.\nlibcugraph-cu12 25.6.0 requires libraft-cu12==25.6.*, but you have libraft-cu12 25.2.0 which is incompatible.\ncudf-polars-cu12 25.6.0 requires pylibcudf-cu12==25.6.*, but you have pylibcudf-cu12 25.2.2 which is incompatible.\npylibcugraph-cu12 25.6.0 requires pylibraft-cu12==25.6.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\npylibcugraph-cu12 25.6.0 requires rmm-cu12==25.6.*, but you have rmm-cu12 25.2.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"# %%writefile train.py\nfrom datasets import load_dataset\n\n# Load dataset\ndataset = load_dataset(\"AIPlans/helpsteer2-helpfulness-preference-cleaned\",split='train')\n\nfrom transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\nfrom peft import LoraConfig, get_peft_model\nfrom trl import ORPOConfig, ORPOTrainer\n\n\nmodel_name = \"Qwen/Qwen3-0.6B\"\n\nbnb_config = BitsAndBytesConfig(\n    load_in_4bit=True,\n    bnb_4bit_compute_dtype=\"bfloat16\",   # or torch.bfloat16\n    bnb_4bit_use_double_quant=True,\n    bnb_4bit_quant_type=\"nf4\",\n)\n\nmodel = AutoModelForCausalLM.from_pretrained(\n    model_name,\n    quantization_config=bnb_config,\n    # device_map=\"auto\",\n)\ntokenizer = AutoTokenizer.from_pretrained(model_name)\n\nlora_config = LoraConfig(\n    r=16,\n    lora_alpha=32,\n    lora_dropout=0.05,\n    target_modules=[\"q_proj\", \"v_proj\"],  # or [\"q_proj\",\"k_proj\",\"v_proj\",\"o_proj\"]\n    task_type=\"CAUSAL_LM\",\n)\nmodel = get_peft_model(model, lora_config)\n\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-27T13:14:36.132277Z","iopub.execute_input":"2025-11-27T13:14:36.132533Z","iopub.status.idle":"2025-11-27T13:15:18.468772Z","shell.execute_reply.started":"2025-11-27T13:14:36.132509Z","shell.execute_reply":"2025-11-27T13:15:18.468161Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"README.md:   0%|          | 0.00/371 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"37d266f41c0e40f1b3718b2f8417aa53"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"data/train-00000-of-00001.parquet:   0%|          | 0.00/13.3M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a095352d480b4dcfb81d78693a0eb830"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/6991 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"bb249ff2947140069d058556c120fa23"}},"metadata":{}},{"name":"stderr","text":"2025-11-27 13:14:45.658996: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1764249285.836136      47 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1764249285.887149      47 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/726 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"665437f134af4ae18595eb2a67ce45d2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/1.50G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"d39f4d3901944ddaa0f11885552fc531"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/239 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b285dddb316642239b6f51ba7fb4658b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"764a1f2e5fde48faad60a4f47814def2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"91cdf63eb20b425f99bc96c248d6dc58"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dbe7b030c862494ca50155c96f027307"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/11.4M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8c6886315b3848debacb3192e17498de"}},"metadata":{}}],"execution_count":2},{"cell_type":"code","source":"training_args = ORPOConfig(output_dir=\"Qwen2-0.6B-ORPO\",report_to=\"none\",    \n                           per_device_train_batch_size=2,\n    gradient_accumulation_steps=8,\n    # max_length=512,\n    # max_prompt_length=384,\n    # key flag:\n    # precompute_ref_log_probs=True,\n    bf16=True,\n    gradient_checkpointing=True,)\n\n\n\ntrainer = ORPOTrainer(model=model, args=training_args, processing_class=tokenizer, train_dataset=dataset)\n\ntrainer.train()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-27T13:15:18.469513Z","iopub.execute_input":"2025-11-27T13:15:18.469725Z","iopub.status.idle":"2025-11-27T21:26:48.986044Z","shell.execute_reply.started":"2025-11-27T13:15:18.469708Z","shell.execute_reply":"2025-11-27T21:26:48.985477Z"}},"outputs":[{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/trl/trainer/orpo_trainer.py:153: UserWarning: This trainer will soon be moved to trl.experimental and is a candidate for removal. If you rely on it and want it to remain, please share your comments here: https://github.com/huggingface/trl/issues/4223. Silence this warning by setting environment variable TRL_EXPERIMENTAL_SILENCE=1.\n  warnings.warn(\nWARNING:trl.trainer.orpo_trainer:When using DPODataCollatorWithPadding, you should set `remove_unused_columns=False` in your TrainingArguments we have set it for you, but you should do it yourself in the future.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/6991 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0519ec37206f4ee788f19d30632ab1a2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/6991 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"28138b9658c4431cba271f918d110e65"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/6991 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5df91f0cf67e4b6b9d7a6e3e18a87b82"}},"metadata":{}},{"name":"stderr","text":"The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'bos_token_id': None, 'pad_token_id': 151643}.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='1311' max='1311' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [1311/1311 8:10:28, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>10</td>\n      <td>1.947900</td>\n    </tr>\n    <tr>\n      <td>20</td>\n      <td>1.999500</td>\n    </tr>\n    <tr>\n      <td>30</td>\n      <td>1.953500</td>\n    </tr>\n    <tr>\n      <td>40</td>\n      <td>1.912900</td>\n    </tr>\n    <tr>\n      <td>50</td>\n      <td>2.035100</td>\n    </tr>\n    <tr>\n      <td>60</td>\n      <td>2.087100</td>\n    </tr>\n    <tr>\n      <td>70</td>\n      <td>1.979400</td>\n    </tr>\n    <tr>\n      <td>80</td>\n      <td>1.979100</td>\n    </tr>\n    <tr>\n      <td>90</td>\n      <td>1.999400</td>\n    </tr>\n    <tr>\n      <td>100</td>\n      <td>2.079300</td>\n    </tr>\n    <tr>\n      <td>110</td>\n      <td>2.106100</td>\n    </tr>\n    <tr>\n      <td>120</td>\n      <td>2.046700</td>\n    </tr>\n    <tr>\n      <td>130</td>\n      <td>1.997900</td>\n    </tr>\n    <tr>\n      <td>140</td>\n      <td>1.907900</td>\n    </tr>\n    <tr>\n      <td>150</td>\n      <td>2.011400</td>\n    </tr>\n    <tr>\n      <td>160</td>\n      <td>2.069500</td>\n    </tr>\n    <tr>\n      <td>170</td>\n      <td>1.931100</td>\n    </tr>\n    <tr>\n      <td>180</td>\n      <td>1.941800</td>\n    </tr>\n    <tr>\n      <td>190</td>\n      <td>2.094500</td>\n    </tr>\n    <tr>\n      <td>200</td>\n      <td>1.997000</td>\n    </tr>\n    <tr>\n      <td>210</td>\n      <td>2.006200</td>\n    </tr>\n    <tr>\n      <td>220</td>\n      <td>2.056900</td>\n    </tr>\n    <tr>\n      <td>230</td>\n      <td>1.989600</td>\n    </tr>\n    <tr>\n      <td>240</td>\n      <td>1.966700</td>\n    </tr>\n    <tr>\n      <td>250</td>\n      <td>1.963500</td>\n    </tr>\n    <tr>\n      <td>260</td>\n      <td>2.051100</td>\n    </tr>\n    <tr>\n      <td>270</td>\n      <td>1.931800</td>\n    </tr>\n    <tr>\n      <td>280</td>\n      <td>1.985000</td>\n    </tr>\n    <tr>\n      <td>290</td>\n      <td>1.891800</td>\n    </tr>\n    <tr>\n      <td>300</td>\n      <td>2.108900</td>\n    </tr>\n    <tr>\n      <td>310</td>\n      <td>1.974900</td>\n    </tr>\n    <tr>\n      <td>320</td>\n      <td>1.942900</td>\n    </tr>\n    <tr>\n      <td>330</td>\n      <td>1.951800</td>\n    </tr>\n    <tr>\n      <td>340</td>\n      <td>1.970400</td>\n    </tr>\n    <tr>\n      <td>350</td>\n      <td>1.959300</td>\n    </tr>\n    <tr>\n      <td>360</td>\n      <td>1.882700</td>\n    </tr>\n    <tr>\n      <td>370</td>\n      <td>1.982000</td>\n    </tr>\n    <tr>\n      <td>380</td>\n      <td>2.112200</td>\n    </tr>\n    <tr>\n      <td>390</td>\n      <td>1.973300</td>\n    </tr>\n    <tr>\n      <td>400</td>\n      <td>1.928500</td>\n    </tr>\n    <tr>\n      <td>410</td>\n      <td>1.949200</td>\n    </tr>\n    <tr>\n      <td>420</td>\n      <td>1.962900</td>\n    </tr>\n    <tr>\n      <td>430</td>\n      <td>1.855300</td>\n    </tr>\n    <tr>\n      <td>440</td>\n      <td>1.928200</td>\n    </tr>\n    <tr>\n      <td>450</td>\n      <td>1.949800</td>\n    </tr>\n    <tr>\n      <td>460</td>\n      <td>1.968900</td>\n    </tr>\n    <tr>\n      <td>470</td>\n      <td>2.029700</td>\n    </tr>\n    <tr>\n      <td>480</td>\n      <td>1.944700</td>\n    </tr>\n    <tr>\n      <td>490</td>\n      <td>1.930400</td>\n    </tr>\n    <tr>\n      <td>500</td>\n      <td>1.994900</td>\n    </tr>\n    <tr>\n      <td>510</td>\n      <td>1.854100</td>\n    </tr>\n    <tr>\n      <td>520</td>\n      <td>1.928700</td>\n    </tr>\n    <tr>\n      <td>530</td>\n      <td>2.006400</td>\n    </tr>\n    <tr>\n      <td>540</td>\n      <td>2.062900</td>\n    </tr>\n    <tr>\n      <td>550</td>\n      <td>1.965500</td>\n    </tr>\n    <tr>\n      <td>560</td>\n      <td>1.909200</td>\n    </tr>\n    <tr>\n      <td>570</td>\n      <td>1.894000</td>\n    </tr>\n    <tr>\n      <td>580</td>\n      <td>1.961100</td>\n    </tr>\n    <tr>\n      <td>590</td>\n      <td>1.844800</td>\n    </tr>\n    <tr>\n      <td>600</td>\n      <td>1.824500</td>\n    </tr>\n    <tr>\n      <td>610</td>\n      <td>1.919800</td>\n    </tr>\n    <tr>\n      <td>620</td>\n      <td>1.943000</td>\n    </tr>\n    <tr>\n      <td>630</td>\n      <td>1.916800</td>\n    </tr>\n    <tr>\n      <td>640</td>\n      <td>1.939100</td>\n    </tr>\n    <tr>\n      <td>650</td>\n      <td>1.911400</td>\n    </tr>\n    <tr>\n      <td>660</td>\n      <td>1.940900</td>\n    </tr>\n    <tr>\n      <td>670</td>\n      <td>1.951500</td>\n    </tr>\n    <tr>\n      <td>680</td>\n      <td>1.942900</td>\n    </tr>\n    <tr>\n      <td>690</td>\n      <td>2.011200</td>\n    </tr>\n    <tr>\n      <td>700</td>\n      <td>1.945900</td>\n    </tr>\n    <tr>\n      <td>710</td>\n      <td>1.938500</td>\n    </tr>\n    <tr>\n      <td>720</td>\n      <td>1.876600</td>\n    </tr>\n    <tr>\n      <td>730</td>\n      <td>1.910200</td>\n    </tr>\n    <tr>\n      <td>740</td>\n      <td>1.912900</td>\n    </tr>\n    <tr>\n      <td>750</td>\n      <td>1.843800</td>\n    </tr>\n    <tr>\n      <td>760</td>\n      <td>1.985100</td>\n    </tr>\n    <tr>\n      <td>770</td>\n      <td>1.871200</td>\n    </tr>\n    <tr>\n      <td>780</td>\n      <td>1.895300</td>\n    </tr>\n    <tr>\n      <td>790</td>\n      <td>1.955600</td>\n    </tr>\n    <tr>\n      <td>800</td>\n      <td>1.892100</td>\n    </tr>\n    <tr>\n      <td>810</td>\n      <td>1.973800</td>\n    </tr>\n    <tr>\n      <td>820</td>\n      <td>1.921400</td>\n    </tr>\n    <tr>\n      <td>830</td>\n      <td>1.939900</td>\n    </tr>\n    <tr>\n      <td>840</td>\n      <td>1.918600</td>\n    </tr>\n    <tr>\n      <td>850</td>\n      <td>1.902200</td>\n    </tr>\n    <tr>\n      <td>860</td>\n      <td>1.957200</td>\n    </tr>\n    <tr>\n      <td>870</td>\n      <td>1.816300</td>\n    </tr>\n    <tr>\n      <td>880</td>\n      <td>1.972200</td>\n    </tr>\n    <tr>\n      <td>890</td>\n      <td>1.986600</td>\n    </tr>\n    <tr>\n      <td>900</td>\n      <td>1.847400</td>\n    </tr>\n    <tr>\n      <td>910</td>\n      <td>1.932600</td>\n    </tr>\n    <tr>\n      <td>920</td>\n      <td>1.870600</td>\n    </tr>\n    <tr>\n      <td>930</td>\n      <td>1.990000</td>\n    </tr>\n    <tr>\n      <td>940</td>\n      <td>1.890400</td>\n    </tr>\n    <tr>\n      <td>950</td>\n      <td>1.967100</td>\n    </tr>\n    <tr>\n      <td>960</td>\n      <td>1.867600</td>\n    </tr>\n    <tr>\n      <td>970</td>\n      <td>1.853000</td>\n    </tr>\n    <tr>\n      <td>980</td>\n      <td>2.018800</td>\n    </tr>\n    <tr>\n      <td>990</td>\n      <td>1.865000</td>\n    </tr>\n    <tr>\n      <td>1000</td>\n      <td>1.941500</td>\n    </tr>\n    <tr>\n      <td>1010</td>\n      <td>1.907700</td>\n    </tr>\n    <tr>\n      <td>1020</td>\n      <td>1.898000</td>\n    </tr>\n    <tr>\n      <td>1030</td>\n      <td>1.864800</td>\n    </tr>\n    <tr>\n      <td>1040</td>\n      <td>1.912100</td>\n    </tr>\n    <tr>\n      <td>1050</td>\n      <td>1.919700</td>\n    </tr>\n    <tr>\n      <td>1060</td>\n      <td>1.867100</td>\n    </tr>\n    <tr>\n      <td>1070</td>\n      <td>1.891300</td>\n    </tr>\n    <tr>\n      <td>1080</td>\n      <td>1.929200</td>\n    </tr>\n    <tr>\n      <td>1090</td>\n      <td>1.930600</td>\n    </tr>\n    <tr>\n      <td>1100</td>\n      <td>1.948100</td>\n    </tr>\n    <tr>\n      <td>1110</td>\n      <td>1.886300</td>\n    </tr>\n    <tr>\n      <td>1120</td>\n      <td>1.852700</td>\n    </tr>\n    <tr>\n      <td>1130</td>\n      <td>1.974500</td>\n    </tr>\n    <tr>\n      <td>1140</td>\n      <td>1.870900</td>\n    </tr>\n    <tr>\n      <td>1150</td>\n      <td>1.945300</td>\n    </tr>\n    <tr>\n      <td>1160</td>\n      <td>1.864200</td>\n    </tr>\n    <tr>\n      <td>1170</td>\n      <td>1.955300</td>\n    </tr>\n    <tr>\n      <td>1180</td>\n      <td>1.934200</td>\n    </tr>\n    <tr>\n      <td>1190</td>\n      <td>1.828900</td>\n    </tr>\n    <tr>\n      <td>1200</td>\n      <td>1.934900</td>\n    </tr>\n    <tr>\n      <td>1210</td>\n      <td>1.890900</td>\n    </tr>\n    <tr>\n      <td>1220</td>\n      <td>1.916200</td>\n    </tr>\n    <tr>\n      <td>1230</td>\n      <td>1.898100</td>\n    </tr>\n    <tr>\n      <td>1240</td>\n      <td>1.940600</td>\n    </tr>\n    <tr>\n      <td>1250</td>\n      <td>1.911300</td>\n    </tr>\n    <tr>\n      <td>1260</td>\n      <td>1.945800</td>\n    </tr>\n    <tr>\n      <td>1270</td>\n      <td>1.918500</td>\n    </tr>\n    <tr>\n      <td>1280</td>\n      <td>1.941700</td>\n    </tr>\n    <tr>\n      <td>1290</td>\n      <td>1.859400</td>\n    </tr>\n    <tr>\n      <td>1300</td>\n      <td>1.821100</td>\n    </tr>\n    <tr>\n      <td>1310</td>\n      <td>1.982100</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"execution_count":3,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=1311, training_loss=1.9430770273885138, metrics={'train_runtime': 29450.9009, 'train_samples_per_second': 0.712, 'train_steps_per_second': 0.045, 'total_flos': 0.0, 'train_loss': 1.9430770273885138, 'epoch': 3.0})"},"metadata":{}}],"execution_count":3},{"cell_type":"code","source":"trainer.save_model(\"Qwen3-0.6B-ORPO2\")\ntokenizer.save_pretrained(\"Qwen3-0.6B-ORPO2\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-27T21:26:48.986711Z","iopub.execute_input":"2025-11-27T21:26:48.986967Z","iopub.status.idle":"2025-11-27T21:26:49.559837Z","shell.execute_reply.started":"2025-11-27T21:26:48.986950Z","shell.execute_reply":"2025-11-27T21:26:49.559100Z"}},"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"('Qwen3-0.6B-ORPO2/tokenizer_config.json',\n 'Qwen3-0.6B-ORPO2/special_tokens_map.json',\n 'Qwen3-0.6B-ORPO2/chat_template.jinja',\n 'Qwen3-0.6B-ORPO2/vocab.json',\n 'Qwen3-0.6B-ORPO2/merges.txt',\n 'Qwen3-0.6B-ORPO2/added_tokens.json',\n 'Qwen3-0.6B-ORPO2/tokenizer.json')"},"metadata":{}}],"execution_count":4},{"cell_type":"code","source":"\n\nfrom transformers import AutoModelForCausalLM, AutoTokenizer\nfrom transformers import AutoModelForCausalLM, AutoTokenizer\n\n# model = AutoModelForCausalLM.from_pretrained(\"Qwen3-0.6B-ORPO2\")\n# tokenizer = AutoTokenizer.from_pretrained(\"Qwen3-0.6B-ORPO2\")\n\nrepo_id = \"AIPlans/Qwen3-0.6B-ORPO\"\n\nmodel.push_to_hub(repo_id)\ntokenizer.push_to_hub(repo_id)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-28T02:55:54.033461Z","iopub.execute_input":"2025-11-28T02:55:54.033826Z","iopub.status.idle":"2025-11-28T02:55:59.520681Z","shell.execute_reply.started":"2025-11-28T02:55:54.033804Z","shell.execute_reply":"2025-11-28T02:55:59.519981Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Processing Files (0 / 0): |          |  0.00B /  0.00B            ","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3dea3a7614b649be85403bedf1bd0f7f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"New Data Upload: |          |  0.00B /  0.00B            ","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"92c59ee2dacd4795bf38286b556102e6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Processing Files (0 / 0): |          |  0.00B /  0.00B            ","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e87cb55366ee4902aeb1b2e56ed7e48a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"New Data Upload: |          |  0.00B /  0.00B            ","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"30f6fd6dc9364bbfabf82fdb491fc270"}},"metadata":{}},{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"CommitInfo(commit_url='https://huggingface.co/AIPlans/Qwen3-0.6B-ORPO/commit/4d0b6fa8e77340f4b654b8b92e8d5199c42428b7', commit_message='Upload tokenizer', commit_description='', oid='4d0b6fa8e77340f4b654b8b92e8d5199c42428b7', pr_url=None, repo_url=RepoUrl('https://huggingface.co/AIPlans/Qwen3-0.6B-ORPO', endpoint='https://huggingface.co', repo_type='model', repo_id='AIPlans/Qwen3-0.6B-ORPO'), pr_revision=None, pr_num=None)"},"metadata":{}}],"execution_count":5},{"cell_type":"code","source":"# !accelerate launch train.py","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-27T21:26:49.560596Z","iopub.execute_input":"2025-11-27T21:26:49.560848Z","iopub.status.idle":"2025-11-27T21:26:49.564665Z","shell.execute_reply.started":"2025-11-27T21:26:49.560830Z","shell.execute_reply":"2025-11-27T21:26:49.564075Z"}},"outputs":[],"execution_count":5},{"cell_type":"markdown","source":"# Eval","metadata":{}},{"cell_type":"code","source":"!pip install -q lm-eval datasets accelerate transformers sentencepiece","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-28T02:52:20.008179Z","iopub.execute_input":"2025-11-28T02:52:20.008855Z","iopub.status.idle":"2025-11-28T02:53:42.224046Z","shell.execute_reply.started":"2025-11-28T02:52:20.008829Z","shell.execute_reply":"2025-11-28T02:53:42.223028Z"}},"outputs":[{"name":"stdout","text":"\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.8/53.8 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m51.8/51.8 kB\u001b[0m \u001b[31m3.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.2/8.2 MB\u001b[0m \u001b[31m92.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.1/84.1 kB\u001b[0m \u001b[31m4.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.7/47.7 MB\u001b[0m \u001b[31m42.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m104.1/104.1 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m5.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m109.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m95.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m48.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m34.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m15.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m2.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m91.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m91.1/91.1 kB\u001b[0m \u001b[31m5.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25h  Building wheel for sqlitedict (setup.py) ... \u001b[?25l\u001b[?25hdone\n  Building wheel for word2number (setup.py) ... \u001b[?25l\u001b[?25hdone\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nbigframes 2.12.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\npylibcudf-cu12 25.2.2 requires pyarrow<20.0.0a0,>=14.0.0; platform_machine == \"x86_64\", but you have pyarrow 22.0.0 which is incompatible.\ncudf-cu12 25.2.2 requires pyarrow<20.0.0a0,>=14.0.0; platform_machine == \"x86_64\", but you have pyarrow 22.0.0 which is incompatible.\nbigframes 2.12.0 requires rich<14,>=12.4.4, but you have rich 14.2.0 which is incompatible.\nlibcugraph-cu12 25.6.0 requires libraft-cu12==25.6.*, but you have libraft-cu12 25.2.0 which is incompatible.\ncudf-polars-cu12 25.6.0 requires pylibcudf-cu12==25.6.*, but you have pylibcudf-cu12 25.2.2 which is incompatible.\npylibcugraph-cu12 25.6.0 requires pylibraft-cu12==25.6.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\npylibcugraph-cu12 25.6.0 requires rmm-cu12==25.6.*, but you have rmm-cu12 25.2.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0m","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"# KTO=\"AIPlans/Qwen3-0.6B-ORPO\"\n# !lm-eval \\\n#   --model hf \\\n#   --model_args pretrained=\"$KTO\" \\\n#   --tasks truthfulqa_mc2,hellaswag,arc_easy,arc_challenge,winogrande \\\n#   --device cuda \\\n#   --batch_size 4 \\\n#   --output_path results_kto.json","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-28T03:12:25.336570Z","iopub.execute_input":"2025-11-28T03:12:25.336860Z","iopub.status.idle":"2025-11-28T03:12:25.340496Z","shell.execute_reply.started":"2025-11-28T03:12:25.336838Z","shell.execute_reply":"2025-11-28T03:12:25.339808Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}