{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":31193,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"pip install -q bitsandbytes trl ","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-11-21T14:25:00.341557Z","iopub.execute_input":"2025-11-21T14:25:00.341812Z","iopub.status.idle":"2025-11-21T14:26:25.199266Z","shell.execute_reply.started":"2025-11-21T14:25:00.341788Z","shell.execute_reply":"2025-11-21T14:26:25.198369Z"}},"outputs":[{"name":"stdout","text":"\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.0/44.0 kB\u001b[0m \u001b[31m1.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.4/59.4 MB\u001b[0m \u001b[31m28.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m465.5/465.5 kB\u001b[0m \u001b[31m23.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m101.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m81.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m47.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m30.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m18.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.0/12.0 MB\u001b[0m \u001b[31m109.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m47.7/47.7 MB\u001b[0m \u001b[31m38.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.3/3.3 MB\u001b[0m \u001b[31m83.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m\n\u001b[?25h\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\nbigframes 2.12.0 requires google-cloud-bigquery-storage<3.0.0,>=2.30.0, which is not installed.\npylibcudf-cu12 25.2.2 requires pyarrow<20.0.0a0,>=14.0.0; platform_machine == \"x86_64\", but you have pyarrow 22.0.0 which is incompatible.\ncudf-cu12 25.2.2 requires pyarrow<20.0.0a0,>=14.0.0; platform_machine == \"x86_64\", but you have pyarrow 22.0.0 which is incompatible.\nbigframes 2.12.0 requires rich<14,>=12.4.4, but you have rich 14.2.0 which is incompatible.\nlibcugraph-cu12 25.6.0 requires libraft-cu12==25.6.*, but you have libraft-cu12 25.2.0 which is incompatible.\ncudf-polars-cu12 25.6.0 requires pylibcudf-cu12==25.6.*, but you have pylibcudf-cu12 25.2.2 which is incompatible.\npylibcugraph-cu12 25.6.0 requires pylibraft-cu12==25.6.*, but you have pylibraft-cu12 25.2.0 which is incompatible.\npylibcugraph-cu12 25.6.0 requires rmm-cu12==25.6.*, but you have rmm-cu12 25.2.0 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"# %%writefile train_dpo.py\nfrom datasets import load_dataset\n\n# Load dataset\nds = load_dataset(\"Jennny/helpsteer2-helpfulness-preference\", split=\"train\")\n\n# Transform function\ndef transform(example):\n    prompt = example[\"chosen\"][0][\"content\"]\n    chosen = example[\"chosen\"][-1][\"content\"]\n    rejected = example[\"rejected\"][-1][\"content\"]\n\n    return {\n        \"prompt\": prompt,\n        \"chosen\": chosen,\n        \"rejected\": rejected,\n        \"margin\": example.get(\"margin\", 0)\n    }\n\n# Convert\ndataset = ds.map(transform, remove_columns=ds.column_names)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-21T14:26:25.201277Z","iopub.execute_input":"2025-11-21T14:26:25.201519Z","iopub.status.idle":"2025-11-21T14:26:32.895194Z","shell.execute_reply.started":"2025-11-21T14:26:25.201487Z","shell.execute_reply":"2025-11-21T14:26:32.894311Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"README.md: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"071e3341b4f142ceb533528f6e19d1bb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"data/train-00000-of-00001.parquet:   0%|          | 0.00/15.8M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"11ded984d387473abbd90728afebb986"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"data/validation-00000-of-00001.parquet:   0%|          | 0.00/807k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ad6021562b5e4009922e88ce93f90ee2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating train split:   0%|          | 0/7221 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fb8b620a200e41338e92bd2b1f5d3237"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Generating validation split:   0%|          | 0/373 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a1a0ca11a9984e2c8e92353d5f56ddc4"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Map:   0%|          | 0/7221 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"05cb63769e0f4df0b605982ae413a9b2"}},"metadata":{}}],"execution_count":2},{"cell_type":"code","source":"from transformers import AutoModelForCausalLM, AutoTokenizer, BitsAndBytesConfig\nfrom peft import LoraConfig, get_peft_model\nfrom trl import KTOConfig, KTOTrainer\n\nmodel_name = \"Qwen/Qwen3-0.6B\"\n\nbnb_config = BitsAndBytesConfig(\n    load_in_4bit=True,\n    bnb_4bit_compute_dtype=\"bfloat16\",   # or torch.bfloat16\n    bnb_4bit_use_double_quant=True,\n    bnb_4bit_quant_type=\"nf4\",\n)\n\nmodel = AutoModelForCausalLM.from_pretrained(\n    model_name,\n    quantization_config=bnb_config,\n    device_map=\"auto\",\n)\ntokenizer = AutoTokenizer.from_pretrained(model_name)\n\nlora_config = LoraConfig(\n    r=16,\n    lora_alpha=32,\n    lora_dropout=0.05,\n    target_modules=[\"q_proj\", \"v_proj\"],  # or [\"q_proj\",\"k_proj\",\"v_proj\",\"o_proj\"]\n    task_type=\"CAUSAL_LM\",\n)\nmodel = get_peft_model(model, lora_config)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-21T14:26:32.895903Z","iopub.execute_input":"2025-11-21T14:26:32.896108Z","iopub.status.idle":"2025-11-21T14:27:12.489248Z","shell.execute_reply.started":"2025-11-21T14:26:32.896082Z","shell.execute_reply":"2025-11-21T14:27:12.488618Z"}},"outputs":[{"name":"stderr","text":"2025-11-21 14:26:39.775583: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1763735199.964593      48 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1763735200.030612      48 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)","\u001b[0;31mAttributeError\u001b[0m: 'MessageFactory' object has no attribute 'GetPrototype'"],"ename":"AttributeError","evalue":"'MessageFactory' object has no attribute 'GetPrototype'","output_type":"error"},{"name":"stderr","text":"/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n  warnings.warn(\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/726 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"9f8b3ff827214a1b8e74b0651dd1a7a7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/1.50G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"17f2b532a3e64862bba039e611b3cb61"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"generation_config.json:   0%|          | 0.00/239 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"58087f7e5044496fbef9717b968e1ccd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"6900e661e8b54d4690be4bfc1b17b3ab"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.json: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4e37c2043cbc4cff9285e4f7fe58801f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"merges.txt: 0.00B [00:00, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"5f5bc4ae47dc4fcabade97dfb252857f"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/11.4M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3e1be7c01a984afc9a7a76cd7e42021a"}},"metadata":{}}],"execution_count":3},{"cell_type":"code","source":"from trl import DPOConfig, DPOTrainer\ntraining_args = DPOConfig(output_dir=\"Qwen2-0.6B-DPO\",report_to=\"none\",    per_device_train_batch_size=2,\n    gradient_accumulation_steps=8,\n    # max_length=512,\n    # max_prompt_length=384,\n    # key flag:\n    precompute_ref_log_probs=True,\n    bf16=True,\n    gradient_checkpointing=True,)\ntrainer = DPOTrainer(model=model, args=training_args, processing_class=tokenizer, train_dataset=dataset)\ntrainer.train()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-21T14:27:12.489981Z","iopub.execute_input":"2025-11-21T14:27:12.490228Z","iopub.status.idle":"2025-11-22T00:04:11.086345Z","shell.execute_reply.started":"2025-11-21T14:27:12.490202Z","shell.execute_reply":"2025-11-22T00:04:11.085690Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Extracting prompt in train dataset:   0%|          | 0/7221 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"83d5b036d56b419cbb9da01086e9d951"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Applying chat template to train dataset:   0%|          | 0/7221 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c2b58393ae5b498f86752037b5366a37"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Tokenizing train dataset:   0%|          | 0/7221 [00:00<?, ? examples/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"df46a1f3d91f4935b3a348c2bb19cc46"}},"metadata":{}},{"name":"stderr","text":"The tokenizer has new PAD/BOS/EOS tokens that differ from the model config and generation config. The model config and generation config were aligned accordingly, being updated with the tokenizer's values. Updated tokens: {'bos_token_id': None, 'pad_token_id': 151643}.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Train dataset reference log probs:   0%|          | 0/3611 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ecc58a73a78740589bbaf165615d40c6"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='1356' max='1356' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [1356/1356 8:23:22, Epoch 3/3]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>10</td>\n      <td>0.689400</td>\n    </tr>\n    <tr>\n      <td>20</td>\n      <td>0.696400</td>\n    </tr>\n    <tr>\n      <td>30</td>\n      <td>0.695000</td>\n    </tr>\n    <tr>\n      <td>40</td>\n      <td>0.690100</td>\n    </tr>\n    <tr>\n      <td>50</td>\n      <td>0.692500</td>\n    </tr>\n    <tr>\n      <td>60</td>\n      <td>0.694500</td>\n    </tr>\n    <tr>\n      <td>70</td>\n      <td>0.695700</td>\n    </tr>\n    <tr>\n      <td>80</td>\n      <td>0.696400</td>\n    </tr>\n    <tr>\n      <td>90</td>\n      <td>0.690800</td>\n    </tr>\n    <tr>\n      <td>100</td>\n      <td>0.689600</td>\n    </tr>\n    <tr>\n      <td>110</td>\n      <td>0.688600</td>\n    </tr>\n    <tr>\n      <td>120</td>\n      <td>0.684400</td>\n    </tr>\n    <tr>\n      <td>130</td>\n      <td>0.682100</td>\n    </tr>\n    <tr>\n      <td>140</td>\n      <td>0.692400</td>\n    </tr>\n    <tr>\n      <td>150</td>\n      <td>0.694100</td>\n    </tr>\n    <tr>\n      <td>160</td>\n      <td>0.687600</td>\n    </tr>\n    <tr>\n      <td>170</td>\n      <td>0.691300</td>\n    </tr>\n    <tr>\n      <td>180</td>\n      <td>0.693400</td>\n    </tr>\n    <tr>\n      <td>190</td>\n      <td>0.694700</td>\n    </tr>\n    <tr>\n      <td>200</td>\n      <td>0.684100</td>\n    </tr>\n    <tr>\n      <td>210</td>\n      <td>0.680800</td>\n    </tr>\n    <tr>\n      <td>220</td>\n      <td>0.681300</td>\n    </tr>\n    <tr>\n      <td>230</td>\n      <td>0.701900</td>\n    </tr>\n    <tr>\n      <td>240</td>\n      <td>0.686500</td>\n    </tr>\n    <tr>\n      <td>250</td>\n      <td>0.686600</td>\n    </tr>\n    <tr>\n      <td>260</td>\n      <td>0.687600</td>\n    </tr>\n    <tr>\n      <td>270</td>\n      <td>0.680200</td>\n    </tr>\n    <tr>\n      <td>280</td>\n      <td>0.685800</td>\n    </tr>\n    <tr>\n      <td>290</td>\n      <td>0.692200</td>\n    </tr>\n    <tr>\n      <td>300</td>\n      <td>0.689300</td>\n    </tr>\n    <tr>\n      <td>310</td>\n      <td>0.686100</td>\n    </tr>\n    <tr>\n      <td>320</td>\n      <td>0.682400</td>\n    </tr>\n    <tr>\n      <td>330</td>\n      <td>0.694300</td>\n    </tr>\n    <tr>\n      <td>340</td>\n      <td>0.692600</td>\n    </tr>\n    <tr>\n      <td>350</td>\n      <td>0.679800</td>\n    </tr>\n    <tr>\n      <td>360</td>\n      <td>0.685000</td>\n    </tr>\n    <tr>\n      <td>370</td>\n      <td>0.679700</td>\n    </tr>\n    <tr>\n      <td>380</td>\n      <td>0.707200</td>\n    </tr>\n    <tr>\n      <td>390</td>\n      <td>0.695900</td>\n    </tr>\n    <tr>\n      <td>400</td>\n      <td>0.689000</td>\n    </tr>\n    <tr>\n      <td>410</td>\n      <td>0.684400</td>\n    </tr>\n    <tr>\n      <td>420</td>\n      <td>0.685900</td>\n    </tr>\n    <tr>\n      <td>430</td>\n      <td>0.670700</td>\n    </tr>\n    <tr>\n      <td>440</td>\n      <td>0.690800</td>\n    </tr>\n    <tr>\n      <td>450</td>\n      <td>0.686000</td>\n    </tr>\n    <tr>\n      <td>460</td>\n      <td>0.675300</td>\n    </tr>\n    <tr>\n      <td>470</td>\n      <td>0.675000</td>\n    </tr>\n    <tr>\n      <td>480</td>\n      <td>0.675300</td>\n    </tr>\n    <tr>\n      <td>490</td>\n      <td>0.677100</td>\n    </tr>\n    <tr>\n      <td>500</td>\n      <td>0.673200</td>\n    </tr>\n    <tr>\n      <td>510</td>\n      <td>0.687900</td>\n    </tr>\n    <tr>\n      <td>520</td>\n      <td>0.673400</td>\n    </tr>\n    <tr>\n      <td>530</td>\n      <td>0.688400</td>\n    </tr>\n    <tr>\n      <td>540</td>\n      <td>0.670600</td>\n    </tr>\n    <tr>\n      <td>550</td>\n      <td>0.671400</td>\n    </tr>\n    <tr>\n      <td>560</td>\n      <td>0.668800</td>\n    </tr>\n    <tr>\n      <td>570</td>\n      <td>0.667600</td>\n    </tr>\n    <tr>\n      <td>580</td>\n      <td>0.671500</td>\n    </tr>\n    <tr>\n      <td>590</td>\n      <td>0.663000</td>\n    </tr>\n    <tr>\n      <td>600</td>\n      <td>0.682000</td>\n    </tr>\n    <tr>\n      <td>610</td>\n      <td>0.683800</td>\n    </tr>\n    <tr>\n      <td>620</td>\n      <td>0.682800</td>\n    </tr>\n    <tr>\n      <td>630</td>\n      <td>0.671900</td>\n    </tr>\n    <tr>\n      <td>640</td>\n      <td>0.677300</td>\n    </tr>\n    <tr>\n      <td>650</td>\n      <td>0.677300</td>\n    </tr>\n    <tr>\n      <td>660</td>\n      <td>0.669100</td>\n    </tr>\n    <tr>\n      <td>670</td>\n      <td>0.675500</td>\n    </tr>\n    <tr>\n      <td>680</td>\n      <td>0.679500</td>\n    </tr>\n    <tr>\n      <td>690</td>\n      <td>0.697100</td>\n    </tr>\n    <tr>\n      <td>700</td>\n      <td>0.688300</td>\n    </tr>\n    <tr>\n      <td>710</td>\n      <td>0.674300</td>\n    </tr>\n    <tr>\n      <td>720</td>\n      <td>0.673000</td>\n    </tr>\n    <tr>\n      <td>730</td>\n      <td>0.683600</td>\n    </tr>\n    <tr>\n      <td>740</td>\n      <td>0.667800</td>\n    </tr>\n    <tr>\n      <td>750</td>\n      <td>0.666200</td>\n    </tr>\n    <tr>\n      <td>760</td>\n      <td>0.665600</td>\n    </tr>\n    <tr>\n      <td>770</td>\n      <td>0.688300</td>\n    </tr>\n    <tr>\n      <td>780</td>\n      <td>0.671500</td>\n    </tr>\n    <tr>\n      <td>790</td>\n      <td>0.659200</td>\n    </tr>\n    <tr>\n      <td>800</td>\n      <td>0.678900</td>\n    </tr>\n    <tr>\n      <td>810</td>\n      <td>0.672000</td>\n    </tr>\n    <tr>\n      <td>820</td>\n      <td>0.669600</td>\n    </tr>\n    <tr>\n      <td>830</td>\n      <td>0.661700</td>\n    </tr>\n    <tr>\n      <td>840</td>\n      <td>0.680800</td>\n    </tr>\n    <tr>\n      <td>850</td>\n      <td>0.665200</td>\n    </tr>\n    <tr>\n      <td>860</td>\n      <td>0.678500</td>\n    </tr>\n    <tr>\n      <td>870</td>\n      <td>0.673900</td>\n    </tr>\n    <tr>\n      <td>880</td>\n      <td>0.683800</td>\n    </tr>\n    <tr>\n      <td>890</td>\n      <td>0.669800</td>\n    </tr>\n    <tr>\n      <td>900</td>\n      <td>0.674000</td>\n    </tr>\n    <tr>\n      <td>910</td>\n      <td>0.673000</td>\n    </tr>\n    <tr>\n      <td>920</td>\n      <td>0.669400</td>\n    </tr>\n    <tr>\n      <td>930</td>\n      <td>0.666200</td>\n    </tr>\n    <tr>\n      <td>940</td>\n      <td>0.667200</td>\n    </tr>\n    <tr>\n      <td>950</td>\n      <td>0.670700</td>\n    </tr>\n    <tr>\n      <td>960</td>\n      <td>0.674500</td>\n    </tr>\n    <tr>\n      <td>970</td>\n      <td>0.671300</td>\n    </tr>\n    <tr>\n      <td>980</td>\n      <td>0.664400</td>\n    </tr>\n    <tr>\n      <td>990</td>\n      <td>0.671000</td>\n    </tr>\n    <tr>\n      <td>1000</td>\n      <td>0.665400</td>\n    </tr>\n    <tr>\n      <td>1010</td>\n      <td>0.674800</td>\n    </tr>\n    <tr>\n      <td>1020</td>\n      <td>0.677600</td>\n    </tr>\n    <tr>\n      <td>1030</td>\n      <td>0.670700</td>\n    </tr>\n    <tr>\n      <td>1040</td>\n      <td>0.675900</td>\n    </tr>\n    <tr>\n      <td>1050</td>\n      <td>0.672300</td>\n    </tr>\n    <tr>\n      <td>1060</td>\n      <td>0.686800</td>\n    </tr>\n    <tr>\n      <td>1070</td>\n      <td>0.675800</td>\n    </tr>\n    <tr>\n      <td>1080</td>\n      <td>0.674200</td>\n    </tr>\n    <tr>\n      <td>1090</td>\n      <td>0.659700</td>\n    </tr>\n    <tr>\n      <td>1100</td>\n      <td>0.660600</td>\n    </tr>\n    <tr>\n      <td>1110</td>\n      <td>0.672400</td>\n    </tr>\n    <tr>\n      <td>1120</td>\n      <td>0.667700</td>\n    </tr>\n    <tr>\n      <td>1130</td>\n      <td>0.687200</td>\n    </tr>\n    <tr>\n      <td>1140</td>\n      <td>0.673400</td>\n    </tr>\n    <tr>\n      <td>1150</td>\n      <td>0.680400</td>\n    </tr>\n    <tr>\n      <td>1160</td>\n      <td>0.671200</td>\n    </tr>\n    <tr>\n      <td>1170</td>\n      <td>0.667000</td>\n    </tr>\n    <tr>\n      <td>1180</td>\n      <td>0.666000</td>\n    </tr>\n    <tr>\n      <td>1190</td>\n      <td>0.673400</td>\n    </tr>\n    <tr>\n      <td>1200</td>\n      <td>0.670600</td>\n    </tr>\n    <tr>\n      <td>1210</td>\n      <td>0.652700</td>\n    </tr>\n    <tr>\n      <td>1220</td>\n      <td>0.656700</td>\n    </tr>\n    <tr>\n      <td>1230</td>\n      <td>0.649900</td>\n    </tr>\n    <tr>\n      <td>1240</td>\n      <td>0.664600</td>\n    </tr>\n    <tr>\n      <td>1250</td>\n      <td>0.653600</td>\n    </tr>\n    <tr>\n      <td>1260</td>\n      <td>0.664000</td>\n    </tr>\n    <tr>\n      <td>1270</td>\n      <td>0.679700</td>\n    </tr>\n    <tr>\n      <td>1280</td>\n      <td>0.670200</td>\n    </tr>\n    <tr>\n      <td>1290</td>\n      <td>0.674000</td>\n    </tr>\n    <tr>\n      <td>1300</td>\n      <td>0.664000</td>\n    </tr>\n    <tr>\n      <td>1310</td>\n      <td>0.676200</td>\n    </tr>\n    <tr>\n      <td>1320</td>\n      <td>0.657200</td>\n    </tr>\n    <tr>\n      <td>1330</td>\n      <td>0.661500</td>\n    </tr>\n    <tr>\n      <td>1340</td>\n      <td>0.666400</td>\n    </tr>\n    <tr>\n      <td>1350</td>\n      <td>0.661200</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=1356, training_loss=0.677575833502069, metrics={'train_runtime': 30224.168, 'train_samples_per_second': 0.717, 'train_steps_per_second': 0.045, 'total_flos': 0.0, 'train_loss': 0.677575833502069, 'epoch': 3.0})"},"metadata":{}}],"execution_count":4},{"cell_type":"markdown","source":"","metadata":{}},{"cell_type":"code","source":"trainer.save_model(\"Qwen3-0.6B-DPO\")\ntokenizer.save_pretrained(\"Qwen3-0.6B-DPO\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-22T00:04:11.087181Z","iopub.execute_input":"2025-11-22T00:04:11.087455Z","iopub.status.idle":"2025-11-22T00:04:11.596611Z","shell.execute_reply.started":"2025-11-22T00:04:11.087425Z","shell.execute_reply":"2025-11-22T00:04:11.595818Z"}},"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"('Qwen3-0.6B-DPO/tokenizer_config.json',\n 'Qwen3-0.6B-DPO/special_tokens_map.json',\n 'Qwen3-0.6B-DPO/chat_template.jinja',\n 'Qwen3-0.6B-DPO/vocab.json',\n 'Qwen3-0.6B-DPO/merges.txt',\n 'Qwen3-0.6B-DPO/added_tokens.json',\n 'Qwen3-0.6B-DPO/tokenizer.json')"},"metadata":{}}],"execution_count":5},{"cell_type":"markdown","source":"# Evals","metadata":{}},{"cell_type":"code","source":"# !pip install -q lm-eval datasets accelerate transformers sentencepiece","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-22T04:02:24.733019Z","iopub.execute_input":"2025-11-22T04:02:24.733826Z","iopub.status.idle":"2025-11-22T04:02:24.737383Z","shell.execute_reply.started":"2025-11-22T04:02:24.733788Z","shell.execute_reply":"2025-11-22T04:02:24.736545Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"KTO=\"AIPlans/Qwen3-0.6B-DPO\"\n!lm-eval \\\n  --model hf \\\n  --model_args pretrained=\"$KTO\" \\\n  --tasks truthfulqa_mc2,hellaswag,arc_easy,arc_challenge,winogrande \\\n  --device cuda \\\n  --batch_size 4 \\\n  --output_path results_kto.json","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-11-22T04:03:49.938488Z","iopub.execute_input":"2025-11-22T04:03:49.939248Z","iopub.status.idle":"2025-11-22T04:37:11.995831Z","shell.execute_reply.started":"2025-11-22T04:03:49.939220Z","shell.execute_reply":"2025-11-22T04:37:11.994930Z"}},"outputs":[{"name":"stdout","text":"2025-11-22 04:03:54.380231: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\nWARNING: All log messages before absl::InitializeLog() is called are written to STDERR\nE0000 00:00:1763784234.402646     143 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\nE0000 00:00:1763784234.410207     143 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\nAttributeError: 'MessageFactory' object has no attribute 'GetPrototype'\nAttributeError: 'MessageFactory' object has no attribute 'GetPrototype'\nAttributeError: 'MessageFactory' object has no attribute 'GetPrototype'\nAttributeError: 'MessageFactory' object has no attribute 'GetPrototype'\nAttributeError: 'MessageFactory' object has no attribute 'GetPrototype'\nINFO:lm_eval.__main__:Selected Tasks: ['arc_challenge', 'arc_easy', 'hellaswag', 'truthfulqa_mc2', 'winogrande']\nINFO:lm_eval.evaluator:Setting random seed to 0 | Setting numpy seed to 1234 | Setting torch manual seed to 1234 | Setting fewshot manual seed to 1234\nINFO:lm_eval.evaluator:Initializing hf model, with arguments: {'pretrained': 'AIPlans/Qwen3-0.6B-DPO'}\nINFO:lm_eval.models.huggingface:Using device 'cuda'\nconfig.json: 100%|█████████████████████████████| 726/726 [00:00<00:00, 4.39MB/s]\ntokenizer_config.json: 5.40kB [00:00, 3.44MB/s]\nvocab.json: 2.78MB [00:00, 7.94MB/s]\nmerges.txt: 1.67MB [00:00, 11.8MB/s]\ntokenizer.json: 100%|██████████████████████| 11.4M/11.4M [00:00<00:00, 15.7MB/s]\nadded_tokens.json: 100%|███████████████████████| 707/707 [00:00<00:00, 5.09MB/s]\nspecial_tokens_map.json: 100%|█████████████████| 613/613 [00:00<00:00, 3.93MB/s]\nchat_template.jinja: 4.17kB [00:00, 7.71MB/s]\nINFO:lm_eval.models.huggingface:Model parallel was set to False, max memory was not set, and device map was set to {'': 'cuda'}\nadapter_config.json: 100%|█████████████████████| 821/821 [00:00<00:00, 9.21MB/s]\nconfig.json: 100%|█████████████████████████████| 726/726 [00:00<00:00, 7.36MB/s]\n/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'repr' attribute with value False was provided to the `Field()` function, which has no effect in the context it was used. 'repr' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n  warnings.warn(\n/usr/local/lib/python3.11/dist-packages/pydantic/_internal/_generate_schema.py:2249: UnsupportedFieldAttributeWarning: The 'frozen' attribute with value True was provided to the `Field()` function, which has no effect in the context it was used. 'frozen' is field-specific metadata, and can only be attached to a model field using `Annotated` metadata or by assignment. This may have happened because an `Annotated` type alias using the `type` statement was used, or if the `Field()` function was attached to a single member of a union type.\n  warnings.warn(\nmodel.safetensors: 100%|████████████████████| 1.50G/1.50G [00:03<00:00, 403MB/s]\ngeneration_config.json: 100%|██████████████████| 239/239 [00:00<00:00, 1.31MB/s]\nadapter_model.safetensors: 100%|███████████| 9.19M/9.19M [00:00<00:00, 9.35MB/s]\nREADME.md: 9.00kB [00:00, 28.9MB/s]\nARC-Challenge/train-00000-of-00001.parqu(…): 100%|█| 190k/190k [00:00<00:00, 985\nARC-Challenge/test-00000-of-00001.parque(…): 100%|█| 204k/204k [00:00<00:00, 803\nARC-Challenge/validation-00000-of-00001.(…): 100%|█| 55.7k/55.7k [00:00<00:00, 3\nGenerating train split: 100%|█████| 1119/1119 [00:00<00:00, 30131.07 examples/s]\nGenerating test split: 100%|█████| 1172/1172 [00:00<00:00, 212544.29 examples/s]\nGenerating validation split: 100%|██| 299/299 [00:00<00:00, 85225.75 examples/s]\nARC-Easy/train-00000-of-00001.parquet: 100%|█| 331k/331k [00:00<00:00, 1.29MB/s]\nARC-Easy/test-00000-of-00001.parquet: 100%|██| 346k/346k [00:00<00:00, 1.41MB/s]\nARC-Easy/validation-00000-of-00001.parqu(…): 100%|█| 86.1k/86.1k [00:00<00:00, 3\nGenerating train split: 100%|████| 2251/2251 [00:00<00:00, 332478.02 examples/s]\nGenerating test split: 100%|█████| 2376/2376 [00:00<00:00, 383767.19 examples/s]\nGenerating validation split: 100%|█| 570/570 [00:00<00:00, 207963.92 examples/s]\nREADME.md: 7.02kB [00:00, 29.4MB/s]\ndata/train-00000-of-00001.parquet: 100%|███| 24.4M/24.4M [00:00<00:00, 68.5MB/s]\ndata/test-00000-of-00001.parquet: 100%|████| 6.11M/6.11M [00:00<00:00, 25.0MB/s]\ndata/validation-00000-of-00001.parquet: 100%|█| 6.32M/6.32M [00:00<00:00, 29.5MB\nGenerating train split: 100%|██| 39905/39905 [00:00<00:00, 263061.14 examples/s]\nGenerating test split: 100%|███| 10003/10003 [00:00<00:00, 260553.47 examples/s]\nGenerating validation split: 100%|█| 10042/10042 [00:00<00:00, 268802.50 example\nMap: 100%|███████████████████████| 39905/39905 [00:06<00:00, 6194.74 examples/s]\nMap: 100%|███████████████████████| 10042/10042 [00:01<00:00, 7181.63 examples/s]\nREADME.md: 9.59kB [00:00, 36.6MB/s]\nmultiple_choice/validation-00000-of-0000(…): 100%|█| 271k/271k [00:00<00:00, 276\nGenerating validation split: 100%|█| 817/817 [00:00<00:00, 171260.25 examples/s]\nREADME.md: 11.2kB [00:00, 36.9MB/s]\nwinogrande_xl/train-00000-of-00001.parqu(…): 100%|█| 2.06M/2.06M [00:00<00:00, 2\nwinogrande_xl/test-00000-of-00001.parque(…): 100%|█| 118k/118k [00:00<00:00, 424\nwinogrande_xl/validation-00000-of-00001.(…): 100%|█| 85.9k/85.9k [00:00<00:00, 4\nGenerating train split: 100%|█| 40398/40398 [00:00<00:00, 1576933.39 examples/s]\nGenerating test split: 100%|█████| 1767/1767 [00:00<00:00, 544270.78 examples/s]\nGenerating validation split: 100%|█| 1267/1267 [00:00<00:00, 452579.05 examples/\nINFO:lm_eval.api.task:Building contexts for winogrande on rank 0...\n100%|███████████████████████████████████| 1267/1267 [00:00<00:00, 106029.19it/s]\nINFO:lm_eval.api.task:Building contexts for truthfulqa_mc2 on rank 0...\n100%|████████████████████████████████████████| 817/817 [00:00<00:00, 841.17it/s]\nINFO:lm_eval.api.task:Building contexts for hellaswag on rank 0...\n100%|███████████████████████████████████| 10042/10042 [00:03<00:00, 2884.98it/s]\nINFO:lm_eval.api.task:Building contexts for arc_easy on rank 0...\n100%|█████████████████████████████████████| 2376/2376 [00:01<00:00, 1262.85it/s]\nINFO:lm_eval.api.task:Building contexts for arc_challenge on rank 0...\n100%|█████████████████████████████████████| 1172/1172 [00:00<00:00, 1190.03it/s]\nINFO:lm_eval.evaluator:Running loglikelihood requests\nRunning loglikelihood requests: 100%|█████| 62772/62772 [31:29<00:00, 33.23it/s]\nfatal: not a git repository (or any parent up to mount point /kaggle)\nStopping at filesystem boundary (GIT_DISCOVERY_ACROSS_FILESYSTEM not set).\nINFO:lm_eval.loggers.evaluation_tracker:Saving results aggregated\nhf (pretrained=AIPlans/Qwen3-0.6B-DPO), gen_kwargs: (None), limit: None, num_fewshot: None, batch_size: 4\n|    Tasks     |Version|Filter|n-shot| Metric |   |Value |   |Stderr|\n|--------------|------:|------|-----:|--------|---|-----:|---|-----:|\n|arc_challenge |      1|none  |     0|acc     |↑  |0.3208|±  |0.0136|\n|              |       |none  |     0|acc_norm|↑  |0.3430|±  |0.0139|\n|arc_easy      |      1|none  |     0|acc     |↑  |0.6103|±  |0.0100|\n|              |       |none  |     0|acc_norm|↑  |0.5589|±  |0.0102|\n|hellaswag     |      1|none  |     0|acc     |↑  |0.3752|±  |0.0048|\n|              |       |none  |     0|acc_norm|↑  |0.4740|±  |0.0050|\n|truthfulqa_mc2|      3|none  |     0|acc     |↑  |0.4305|±  |0.0145|\n|winogrande    |      1|none  |     0|acc     |↑  |0.5620|±  |0.0139|\n\n","output_type":"stream"}],"execution_count":4},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}